{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we set out exercises to implement error metrics and use them in skforecast. The solutions we show are only one way of answering these questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data has been obtained from [Store Item Demand Forecasting Challenge](https://www.kaggle.com/competitions/demand-forecasting-kernels-only/data), specifically `train.csv`. This dataset contains 913,000 sales transactions from 2013–01–01 to 2017–12–31 for 50 products (SKU) in 10 stores. The goal is to predict the next 7 days sales for 50 different items in one store using the available 5 years history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.datasets import fetch_dataset\n",
    "\n",
    "# Load the data\n",
    "data = fetch_dataset(name=\"store_sales\", raw=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ForecasterRecursiveMultiSeries` requires that each time series is a column in the dataframe and that the index is time-like (datetime or timestamp). \n",
    "\n",
    "So now we process the data to get dataframes in the required format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "\n",
    "selected_store = 2\n",
    "selected_items = data.item.unique()  # All items\n",
    "# selected_items = [1, 2, 3, 4, 5] # Selection of items to reduce computation time\n",
    "\n",
    "# Filter data to specific stores and products\n",
    "mask = (data[\"store\"] == selected_store) & (data[\"item\"].isin(selected_items))\n",
    "data = data[mask].copy()\n",
    "\n",
    "# Convert `date` column to datetime\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "# Convert to one column per time series\n",
    "data = pd.pivot_table(data=data, values=\"sales\", index=\"date\", columns=\"item\")\n",
    "\n",
    "# Reset column names\n",
    "data.columns.name = None\n",
    "data.columns = [f\"item_{col}\" for col in data.columns]\n",
    "\n",
    "# Explicitly set the frequency of the data to daily.\n",
    "# This would introduce missing values for missing days.\n",
    "data = data.asfreq(\"1D\")\n",
    "\n",
    "# Sort by time\n",
    "data = data.sort_index()\n",
    "\n",
    "data.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any missing values introduced\n",
    "data.isnull().sum().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a subset of the time series\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "data.iloc[:, :4].plot(\n",
    "    legend=True,\n",
    "    subplots=True,\n",
    "    sharex=True,\n",
    "    title=\"Sales of store 2\",\n",
    "    ax=ax,\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the day of the week to use as an exogenous feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"day_of_week\"] = data.index.weekday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build an intuition about the characteristics (trend, outliers, seasonality, intermittency, etc.) and the range of values that the time series have.\n",
    "This helps when deciding which error metrics to use.\n",
    "\n",
    "Compute a set of summary statistics and/or plots to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 5 largest and 5 smallest time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for any zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing custom error metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error metrics that we can consider using are:\n",
    "- To measure the bias: \n",
    "    - Average forecast bias: we compute the forecast bias, which is a scale independent measure, for each time series and then average over all time series.\n",
    "- To measure the error:\n",
    "    - Normalised RMSE or normalised deviation: these are pooled error metrics, which cannot currently be calculated natively in skforecast.\n",
    "    - Average RMSSE or MASE:  we can compute the MASE or RMSSE, a scale independent metric, for each time series individually and then average the results to give our final metric. This cannot currently be calculated in skforecast as it requires the custom error function to have\n",
    "    access to the training set. \n",
    "    - Average WAPE: we can compute the WAPE, a scale independent metric, for each time series individually and then average the results to give our final metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes `y_true` and `y_pred` as an argument and ouputs the \n",
    "weighted mean absolute percentage error (WAPE) metric defined as:\n",
    "\n",
    "$ WAPE = \\frac{\\sum_t{|e_t|}}{\\sum_t{|y_t|}} $\n",
    "\n",
    "Note: The data does have trend, this would suggest we should not use WAPE. However,\n",
    "as we are only forecasting 7 days into the future the magnitude of the trend in\n",
    "the forecast horizon is negligible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes `y_true` and `y_pred` as an argument and ouputs the \n",
    "forecast bias metric defined as the mean error divided by the mean of the time series\n",
    "in the forecast horizon:\n",
    "\n",
    "$ FB = \\frac{1/H\\sum_t{e_t}}{1/H\\sum_t{y_t}} = \\frac{\\sum_t{e_t}}{\\sum_t{y_t}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a custom error metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model to do recursive multistep forecasting for multiple independent time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform backtesting with refitting at every backtest step and compute the forecast bias\n",
    "and WAPE for each time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skforecast.model_selection import backtesting_forecaster_multiseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average the forecast bias and WAPE over all items to get a single value for each\n",
    "metric. Does your model over or under forecast?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a sample of the largest and smallest WAPE time series and their backtest\n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcst-ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
